{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"review_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restrict dates to be after 2018-01-01\n",
    "df = df[df[\"date\"] >= \"2018-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use bertopic to create topics and show the trend of topics over time\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bertopic on a single company\n",
    "company = \"Google\"\n",
    "\n",
    "from umap import UMAP\n",
    "# create umap instance to save state\n",
    "umap_model = UMAP(n_neighbors=15, n_components=10, metric='cosine', low_memory=False, random_state=42)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model, umap_model=umap_model, nr_topics=\"auto\", diversity=0.2)\n",
    "\n",
    "# create list of merged pros and cons\n",
    "docs = df[df[\"company\"] == company][\"pros\"] + \". \" + df[df[\"company\"] == company][\"cons\"]\n",
    "docs = docs.tolist()\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "df[\"date\"] = df[\"date\"].apply(lambda x: x.replace(day=1))\n",
    "timestamps = df[df[\"company\"] == company].date.to_list()\n",
    "\n",
    "topics_over_time = topic_model.topics_over_time(docs, timestamps)\n",
    "topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrangling to make sure there is data for all topics for all timestamps\n",
    "freq_df = topic_model.get_topic_freq()\n",
    "freq_df = freq_df.loc[freq_df.Topic != -1, :]\n",
    "# group by Timestamp and count rows in each group\n",
    "chosen_topics = sorted(freq_df.Topic.to_list()[:10])\n",
    "# remove all rows where Topic isn't in chosen_topics\n",
    "topics_over_time = topics_over_time[topics_over_time[\"Topic\"].isin(chosen_topics)]\n",
    "#add a row to data if for a given timestamp a topic in chosen_topics doesn't exist\n",
    "for topic in chosen_topics:\n",
    "    for timestamp in topics_over_time.Timestamp.unique():\n",
    "        if topic not in topics_over_time[topics_over_time[\"Timestamp\"] == timestamp][\"Topic\"].to_list():\n",
    "            topics_over_time = topics_over_time.append({\"Timestamp\": timestamp, \"Topic\": topic, \"Count\": 0}, ignore_index=True)\n",
    "# impute nan values in frequency to 0\n",
    "topics_over_time[\"Frequency\"] = topics_over_time[\"Frequency\"].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column \"relative_frequency\" where the relative frequency is calculated grouped on Timestamp\n",
    "topics_over_time[\"relative_frequency\"] = topics_over_time.groupby(\"Timestamp\")[\"Frequency\"].apply(lambda x: x / x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing package\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "\n",
    "#for each sorted timestamp in topics_over_time, get the relative frequency for each topic\n",
    "data = topics_over_time.sort_values([\"Timestamp\", \"Topic\"]).groupby(\"Timestamp\").apply(lambda x: x[\"relative_frequency\"].to_list())\n",
    "\n",
    "_list = []\n",
    "for row in data.iteritems():\n",
    "    value = [str(row[0])[:10]]\n",
    "    value.extend(row[1])\n",
    "    _list.append(value)\n",
    "\n",
    "# create data\n",
    "df = pd.DataFrame(_list,\n",
    "                  columns=['Time', \"Company Culture\", \"Company Employee\", \"Teamwork\", \"Internship experience\", \"Engineering culture\", \"Perks and work life balance\", \"Promotions and work life\", \"Work life balance and growth\", \"Positive Aspects\", \"Campus and cantine\"])\n",
    "# view data \n",
    "# plot data in stack manner of bar type\n",
    "ax = df.plot(x='Time', kind='bar', stacked=True,\n",
    "        title='', width=0.7)\n",
    "\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "    \n",
    "mpl.rcParams.update({\n",
    "    'legend.frameon' : 'True',\n",
    "    'legend.facecolor' : (1.0, 1.0, 1.0),\n",
    "    'legend.framealpha' : 1.0,\n",
    "    'legend.edgecolor' : 'white',\n",
    "})\n",
    "ax.set_facecolor(\"white\")\n",
    "ax.legend(loc='lower right', fontsize=18)\n",
    "#ax xtick font size\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "# remove every second ytick label\n",
    "xticks = ax.get_xticks()\n",
    "xticks = xticks[::2]\n",
    "plt.xticks(xticks, fontsize=20)\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "ax.set_ylabel(\"Relative Frequency\", fontsize=20)\n",
    "ax.set_xlabel(\"Time\", fontsize=20)\n",
    "# make plot wider\n",
    "plt.gcf().set_size_inches(20, 10)\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "\n",
    "# set facecolor to white\n",
    "# reduce space between bars\n",
    "\n",
    "plt.savefig(\"relativefrequencytopicgoogle.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing package\n",
    "#for each sorted timestamp in topics_over_time, get the relative frequency for each topic\n",
    "data = topics_over_time.sort_values([\"Timestamp\", \"Topic\"]).groupby(\"Timestamp\").apply(lambda x: x[\"Frequency\"].to_list())\n",
    "\n",
    "_list = []\n",
    "for row in data.iteritems():\n",
    "    value = [str(row[0])[:10]]\n",
    "    value.extend(row[1])\n",
    "    _list.append(value)\n",
    "\n",
    "# create data\n",
    "df = pd.DataFrame(_list,\n",
    "                  columns=['Time', \"Company Culture\", \"Company Employee\", \"Teamwork\", \"Internship experience\", \"Engineering culture\", \"Perks and work life balance\", \"Promotions and work life\", \"Work life balance and growth\", \"Positive Aspects\", \"Campus and cantine\"])\n",
    "# view data \n",
    "# plot data in stack manner of bar type\n",
    "ax = df.plot(x='Time', kind='bar', stacked=True,\n",
    "        title='', width=0.7)\n",
    "\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    'legend.frameon' : 'True',\n",
    "    'legend.facecolor' : (1.0, 1.0, 1.0),\n",
    "    'legend.framealpha' : 1.0,\n",
    "    'legend.edgecolor' : 'white',\n",
    "})\n",
    "ax.set_facecolor(\"white\")\n",
    "ax.legend(loc='upper left', fontsize=20)\n",
    "#ax xtick font size\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "# remove every second ytick label\n",
    "xticks = ax.get_xticks()\n",
    "xticks = xticks[::2]\n",
    "plt.xticks(xticks, fontsize=20)\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=20)\n",
    "ax.set_xlabel(\"Time\", fontsize=20)\n",
    "# make plot wider\n",
    "plt.gcf().set_size_inches(20, 10)\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "\n",
    "# set facecolor to white\n",
    "# reduce space between bars\n",
    "\n",
    "plt.savefig(\"frequencytopicgoogle.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all 5 best keywords for 10 best topics\n",
    "keywords = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    output = \"\"\n",
    "    for keyword in topic_model.get_topic(i)[:5]:\n",
    "        output += \", {}\".format(keyword[0], round(keyword[1], 2))\n",
    "    output = output[2:]\n",
    "    keywords.append(output)\n",
    "\n",
    "#print them for manual inspection\n",
    "keywords\n",
    "\n",
    "#These topics are derived from the keywords\n",
    "###########################################\n",
    "# Company culture\n",
    "# Company benefits and growth opportunities\n",
    "# Company amenities\n",
    "# Internship experience\n",
    "# Engineering culture\n",
    "# salary and hours\n",
    "# Experience and opportunities to learn\n",
    "# Cooperation and teamwork\n",
    "# Work life balance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DITW_exam_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a55f66077803f5ce433cf01f24cef786becd55b3a902f9ffdec67c5b56f8f68d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
