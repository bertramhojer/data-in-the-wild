{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from glob import glob\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy import signal\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('data.csv')\n",
    "stock_df = pd.read_parquet(\"stock_data/financial_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['date'] = [pd.to_datetime(date) for date in review_df.date]\n",
    "review_df['year'] = [date.year for date in review_df.date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_reviews(data, start_date, end_date, window_size=7, spill_over=3):\n",
    "\n",
    "    end = pd.to_datetime(end_date)\n",
    "    ratings = list()\n",
    "    i = pd.to_datetime(start_date)\n",
    "    j = i + dt.timedelta(days=window_size)\n",
    "\n",
    "    while j < end:\n",
    "        i_window = i - dt.timedelta(days=spill_over)\n",
    "        j_window = j + dt.timedelta(days=spill_over)\n",
    "        subset = data[(data.index >= i_window) & (data.index < j_window)]\n",
    "        if (n := len(subset)) == 0:\n",
    "            ratings.append((np.nan, n, i))\n",
    "        else:\n",
    "            avg_rating = np.mean(subset)\n",
    "            ratings.append((avg_rating, n, i))\n",
    "\n",
    "        i, j = j, j + dt.timedelta(days=window_size)\n",
    "\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def rolling_stocks(data, start_date, end_date, window_size=7, spill_over=3):\n",
    "\n",
    "    end = pd.to_datetime(end_date)\n",
    "    ratings = list()\n",
    "    i = pd.to_datetime(start_date)\n",
    "    j = i + dt.timedelta(days=window_size)\n",
    "\n",
    "    while j < end:\n",
    "        i_window = i - dt.timedelta(days=spill_over)\n",
    "        j_window = j + dt.timedelta(days=spill_over)\n",
    "        subset = data[(data.index >= i_window) & (data.index < j_window)]\n",
    "        if (n := len(subset)) == 0:\n",
    "            ratings.append((np.nan, n, i))\n",
    "        else:\n",
    "            avg_rating = np.mean(subset)\n",
    "            ratings.append((avg_rating, n, i))\n",
    "\n",
    "        i, j = j, j + dt.timedelta(days=window_size)\n",
    "\n",
    "    return ratings\n",
    "\n",
    "# zi = (xi – min(x)) / (max(x) – min(x))\n",
    "def scale(x, x_max, x_min):\n",
    "\n",
    "    z = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrangling(stock_df, review_df, company, start_date, end_date, window_size, spill_over):\n",
    "    \"\"\"\n",
    "    This implementation scales first and then creates the rolling average over week which is then plotted.\n",
    "    This in turn makes it such that none of the weeks plotted are at the minimum for Glassdoor ratings (problem?).\n",
    "    \"\"\"\n",
    "\n",
    "    if company=='Apple':\n",
    "        comp_tag = 'AAPL'\n",
    "    elif company=='Meta':\n",
    "        comp_tag = 'META'\n",
    "    elif company=='Google':\n",
    "        comp_tag = 'GOOG'\n",
    "    elif company=='Amazon':\n",
    "        comp_tag = 'AMZN'\n",
    "    elif company=='Microsoft':\n",
    "        comp_tag = 'MSFT'\n",
    "    elif company=='Nvidia':\n",
    "        comp_tag = 'NVDA'\n",
    "    elif company=='Tesla':\n",
    "        comp_tag = 'TSLA'\n",
    "\n",
    "    start, end = pd.to_datetime(start_date), pd.to_datetime(end_date)\n",
    "    stocks = stock_df[comp_tag]\n",
    "    stocks = stocks[(stocks.index >= start) & (stocks.index < end)]\n",
    "\n",
    "    reviews = review_df[review_df[\"company\"]==f\"{company}\"]\n",
    "    reviews['rating'] = reviews.rating.apply(float)\n",
    "    reviews['date'] = [pd.to_datetime(date) for date in reviews.date]\n",
    "    reviews = reviews[(reviews.date >= start) & (reviews.date < end)]\n",
    "    reviews = reviews.groupby('date').mean().fillna(np.mean(reviews))\n",
    "\n",
    "    reviews = scale(reviews.rating, max(reviews.rating), min(reviews.rating))\n",
    "\n",
    "    stocks = scale(stocks['Adj Close'], np.nanmax(stocks['Adj Close']), np.nanmin(stocks['Adj Close']))\n",
    "    reviews_smoothed = rolling_reviews(reviews, start, end, window_size=window_size, spill_over=spill_over)\n",
    "    stocks_smoothed = rolling_stocks(stocks, start, end, window_size=window_size, spill_over=spill_over)\n",
    "\n",
    "    return reviews_smoothed, stocks_smoothed, stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_smoothed_apple, stocks_smoothed_apple, stocks_apple_nosmooth = data_wrangling(stock_df, review_df, 'Apple', '2020-01-01', '2022-10-01', 7, 2)\n",
    "ratings_apple, _, rating_dates_apple = zip(*reviews_smoothed_apple)\n",
    "stocks_apple, _, stock_dates_apple = zip(*stocks_smoothed_apple)\n",
    "\n",
    "reviews_smoothed_amazon, stocks_smoothed_amazon, stocks_amazon_nosmooth = data_wrangling(stock_df, review_df, 'Amazon', '2020-01-01', '2022-10-01', 7, 2)\n",
    "ratings_amazon, _, rating_dates_amazon = zip(*reviews_smoothed_amazon)\n",
    "stocks_amazon, _, stock_dates_amazon = zip(*stocks_smoothed_amazon)\n",
    "\n",
    "reviews_smoothed_meta, stocks_smoothed_meta, stocks_meta_nosmooth = data_wrangling(stock_df, review_df, 'Meta', '2020-01-01', '2022-10-01', 7, 2)\n",
    "ratings_meta, _, rating_dates_meta = zip(*reviews_smoothed_meta)\n",
    "stocks_meta, _, stock_dates_meta = zip(*stocks_smoothed_meta)\n",
    "\n",
    "reviews_smoothed_google, stocks_smoothed_google, stocks_google_nosmooth = data_wrangling(stock_df, review_df, 'Google', '2020-01-01', '2022-10-01', 7, 2)\n",
    "ratings_google, _, rating_dates_google = zip(*reviews_smoothed_google)\n",
    "stocks_google, _, stock_dates_google = zip(*stocks_smoothed_google)\n",
    "\n",
    "reviews_smoothed_microsoft, stocks_smoothed_microsoft, stocks_microsoft_nosmooth = data_wrangling(stock_df, review_df, 'Microsoft', '2020-01-01', '2022-10-01', 7, 2)\n",
    "ratings_microsoft, _, rating_dates_microsoft = zip(*reviews_smoothed_microsoft)\n",
    "stocks_microsoft, _, stock_dates_microsoft = zip(*stocks_smoothed_microsoft)\n",
    "\n",
    "reviews_smoothed_nvidia, stocks_smoothed_nvidia, stocks_nvidia_nosmooth = data_wrangling(stock_df, review_df, 'Nvidia', '2020-01-01', '2022-10-01', 7, 2)\n",
    "ratings_nvidia, _, rating_dates_nvidia = zip(*reviews_smoothed_nvidia)\n",
    "stocks_nvidia, _, stock_dates_nvidia = zip(*stocks_smoothed_nvidia)\n",
    "\n",
    "reviews_smoothed_tesla, stocks_smoothed_tesla, stocks_tesla_nosmooth = data_wrangling(stock_df, review_df, 'Tesla', '2020-01-01', '2022-10-01', 7, 2)\n",
    "ratings_tesla, _, rating_dates_tesla = zip(*reviews_smoothed_tesla)\n",
    "stocks_tesla, _, stock_dates_tesla = zip(*stocks_smoothed_tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(company, ax, ratings, stocks, dates, stocks_df, with_legend=False, with_date=False):\n",
    "    \"\"\"\n",
    "    Potentially add a color for the values imputed with the mean.\n",
    "    \"\"\"\n",
    "\n",
    "    mu = np.nanmean(ratings)\n",
    "    ratings = pd.Series(ratings).fillna(mu)\n",
    "\n",
    "    axis = ax.set_title(company)\n",
    "    axis = ax.set_facecolor(\"white\")\n",
    "    axis = ax.plot(dates, ratings, color=\"red\", label='aggregated rating')\n",
    "    axis = ax.plot(dates, stocks, color=\"blue\", label='aggregated stock')\n",
    "    axis = ax.plot(stocks_df.index, stocks_df, color=\"blue\", alpha=.3, label='stock')\n",
    "    if with_legend:\n",
    "        axis = ax.legend(loc=\"upper left\")\n",
    "\n",
    "    return axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('bmh')\n",
    "\n",
    "fig, axes = plt.subplots(7, 1, figsize=(10, 14))\n",
    "fig.suptitle('Aggregated Review Ratings v. Stock Price by Week', weight='bold', fontsize=16)\n",
    "\n",
    "fig.text(0.51, -.01, 'Date', ha='center', fontsize=14)\n",
    "fig.text(-.01, 0.5, 'Scaled Avg. Review Rating & Stock Price', fontsize=14, va='center', rotation='vertical')\n",
    "\n",
    "ax1, ax2, ax3, ax4, ax5, ax6, ax7 = axes\n",
    "\n",
    "plot_series('Apple', ax1, ratings_apple, stocks_apple, rating_dates_apple, stocks_apple_nosmooth, with_legend=True)\n",
    "plot_series('Amazon', ax2, ratings_amazon, stocks_amazon, rating_dates_amazon, stocks_amazon_nosmooth)\n",
    "plot_series('Google', ax3, ratings_google, stocks_google, rating_dates_google, stocks_google_nosmooth)\n",
    "plot_series('Meta', ax4, ratings_meta, stocks_meta, rating_dates_meta, stocks_meta_nosmooth)\n",
    "plot_series('Microsoft', ax5, ratings_microsoft, stocks_microsoft, rating_dates_microsoft, stocks_microsoft_nosmooth)\n",
    "plot_series('Nvidia', ax6, ratings_nvidia, stocks_nvidia, rating_dates_nvidia, stocks_nvidia_nosmooth)\n",
    "plot_series('Tesla', ax7, ratings_tesla, stocks_tesla, rating_dates_tesla, stocks_tesla_nosmooth)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_analysis(review_df, stock_df, company, start_date, end_date):\n",
    "\n",
    "    if company=='Apple':\n",
    "        comp_tag = 'AAPL'\n",
    "    elif company=='Meta':\n",
    "        comp_tag = 'META'\n",
    "    elif company=='Google':\n",
    "        comp_tag = 'GOOG'\n",
    "    elif company=='Amazon':\n",
    "        comp_tag = 'AMZN'\n",
    "    elif company=='Microsoft':\n",
    "        comp_tag = 'MSFT'\n",
    "    elif company=='Nvidia':\n",
    "        comp_tag = 'NVDA'\n",
    "    elif company=='Tesla':\n",
    "        comp_tag = 'TSLA'\n",
    "    \n",
    "    start, end = pd.to_datetime(start_date), pd.to_datetime(end_date)\n",
    "\n",
    "    reviews = review_df[review_df.company==company][['rating', 'date']]\n",
    "    reviews['date'] = [pd.to_datetime(date) for date in reviews.date]\n",
    "    reviews = reviews[(reviews.date >= start) & (reviews.date < end)]\n",
    "    reviews['rating'] = reviews.rating.apply(float)\n",
    "    reviews = reviews.groupby('date').mean()\n",
    "\n",
    "    stocks = stock_df[comp_tag][['Adj Close']].dropna().rename(columns={'Adj Close': 'price'})\n",
    "    stocks = stocks[(stocks.index >= start) & (stocks.index < end)]\n",
    "\n",
    "    agg_reviews = pd.DataFrame()\n",
    "    agg_reviews['rating'] = reviews.rating\n",
    "    agg_reviews['date'] = pd.to_datetime(reviews.index - pd.to_timedelta(7, unit='d'))\n",
    "    agg_reviews = agg_reviews.groupby(pd.Grouper(key='date', freq='W-MON'))['rating'].mean().reset_index().sort_values('date').fillna(np.mean(agg_reviews.rating))\n",
    "    \n",
    "    rolling_reviews = reviews.rating.rolling(window=31, min_periods=1).mean()\n",
    "    detrended_reviews = (reviews.rating - rolling_reviews)\n",
    "\n",
    "    agg_stocks = pd.DataFrame()\n",
    "    agg_stocks['price'] = stocks\n",
    "    agg_stocks['date'] = pd.to_datetime(stocks.index - pd.to_timedelta(7, unit='d'))\n",
    "    agg_stocks = agg_stocks.groupby(pd.Grouper(key='date', freq='W-MON'))['price'].last().reset_index().sort_values('date')\n",
    "\n",
    "    rolling_stocks = agg_stocks.price.rolling(window=4, min_periods=1).mean()\n",
    "    detrended_stocks = (agg_stocks.price - rolling_stocks)\n",
    "\n",
    "    return agg_reviews, detrended_reviews, agg_stocks, detrended_stocks\n",
    "\n",
    "\n",
    "def adf_test(timeseries):\n",
    "\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    result = pd.Series(dftest[0:4], index=['Test Statistic','P-value','Lags Used','No of Observations'])\n",
    "    \n",
    "    for key,value in dftest[4].items():\n",
    "        result['Critical Value (%s)'%key] = value\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def cc_values(series1, series2):\n",
    "\n",
    "    lags = signal.correlation_lags(len(series1), len(series2))\n",
    "    p = series1\n",
    "    q = series2\n",
    "    p = (p - np.mean(p)) / (np.std(p) * len(p))\n",
    "    q = (q - np.mean(q)) / (np.std(q))  \n",
    "    c = np.correlate(p, q, 'full')\n",
    "\n",
    "    return c, lags\n",
    "\n",
    "\n",
    "def cc_plot(lags, cc, company):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.plot(lags, cc)\n",
    "    ax.axhline(-2/np.sqrt(23), color='red', label='5% confidence interval')\n",
    "    ax.axhline(2/np.sqrt(23), color='red')\n",
    "    ax.axvline(x = 0, color = 'black', lw = 1)\n",
    "    ax.axhline(y = 0, color = 'black', lw = 1)\n",
    "    ax.axhline(y = np.max(cc), color = 'blue', lw = 1, \n",
    "    linestyle='--', label = 'highest +/- correlation')\n",
    "    ax.axhline(y = np.min(cc), color = 'blue', lw = 1, \n",
    "    linestyle='--')\n",
    "    ax.set(ylim = [-1, 1])\n",
    "    ax.set_title(f'Cross Correlation: {company} Employee Reviews and Stock Price', fontsize = 15)\n",
    "    ax.set_ylabel('Correlation Coefficients', \n",
    "    fontsize = 12)\n",
    "    ax.set_xlabel('Time Lags', fontsize = 12)\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY = \"Apple\"\n",
    "\n",
    "agg_reviews, detrended_reviews, agg_stocks, detrended_stocks = pre_analysis(review_df, stock_df, COMPANY, '2020-01-01', '2022-10-01')\n",
    "\n",
    "print(adf_test(agg_reviews.rating)['P-value'])\n",
    "print(adf_test(detrended_stocks)['P-value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY = \"Google\"\n",
    "agg_reviews, detrended_reviews, agg_stocks, detrended_stocks = pre_analysis(review_df, stock_df, COMPANY, '2020-01-01', '2022-10-01')\n",
    "\n",
    "cc_matrix, lags = cc_values(agg_reviews.rating, detrended_stocks)\n",
    "print(\"Maximum correlation index: \", cor_index:=np.unravel_index(np.argmax(cc_matrix, axis=None), cc_matrix.shape)[0], \"\\n\",\n",
    "        \"Correlation of: \", cc_matrix[cor_index])\n",
    "cc_plot(lags, cc_matrix, COMPANY)\n",
    "plt.savefig(f\"cross-correlation-{COMPANY}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY = \"Apple\"\n",
    "agg_reviews, detrended_reviews, agg_stocks, detrended_stocks = pre_analysis(review_df, stock_df, COMPANY, '2020-01-01', '2022-10-01')\n",
    "\n",
    "cc_matrix, lags = cc_values(agg_reviews.rating, detrended_stocks)\n",
    "print(\"Maximum correlation index: \", cor_index:=np.unravel_index(np.argmax(cc_matrix, axis=None), cc_matrix.shape)[0], \"\\n\",\n",
    "        \"Correlation of: \", cc_matrix[cor_index])\n",
    "cc_plot(lags, cc_matrix, COMPANY)\n",
    "plt.savefig(f\"cross-correlation-{COMPANY}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY = \"Meta\"\n",
    "agg_reviews, detrended_reviews, agg_stocks, detrended_stocks = pre_analysis(review_df, stock_df, COMPANY, '2020-01-01', '2022-10-01')\n",
    "\n",
    "cc_matrix, lags = cc_values(agg_reviews.rating, detrended_stocks)\n",
    "print(\"Maximum correlation index: \", cor_index:=np.unravel_index(np.argmax(cc_matrix, axis=None), cc_matrix.shape)[0], \"\\n\",\n",
    "        \"Correlation of: \", cc_matrix[cor_index])\n",
    "cc_plot(lags, cc_matrix, COMPANY)\n",
    "plt.savefig(f\"cross-correlation-{COMPANY}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY = \"Amazon\"\n",
    "agg_reviews, detrended_reviews, agg_stocks, detrended_stocks = pre_analysis(review_df, stock_df, COMPANY, '2020-01-01', '2022-10-01')\n",
    "\n",
    "cc_matrix, lags = cc_values(agg_reviews.rating, detrended_stocks)\n",
    "print(\"Maximum correlation index: \", cor_index:=np.unravel_index(np.argmax(cc_matrix, axis=None), cc_matrix.shape)[0], \"\\n\",\n",
    "        \"Correlation of: \", cc_matrix[cor_index])\n",
    "cc_plot(lags, cc_matrix, COMPANY)\n",
    "plt.savefig(f\"cross-correlation-{COMPANY}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY = \"Microsoft\"\n",
    "agg_reviews, detrended_reviews, agg_stocks, detrended_stocks = pre_analysis(review_df, stock_df, COMPANY, '2020-01-01', '2022-10-01')\n",
    "\n",
    "cc_matrix, lags = cc_values(agg_reviews.rating, detrended_stocks)\n",
    "print(\"Maximum correlation index: \", cor_index:=np.unravel_index(np.argmax(cc_matrix, axis=None), cc_matrix.shape)[0], \"\\n\",\n",
    "        \"Correlation of: \", cc_matrix[cor_index])\n",
    "cc_plot(lags, cc_matrix, COMPANY)\n",
    "plt.savefig(f\"cross-correlation-{COMPANY}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY = \"Nvidia\"\n",
    "agg_reviews, detrended_reviews, agg_stocks, detrended_stocks = pre_analysis(review_df, stock_df, COMPANY, '2020-01-01', '2022-10-01')\n",
    "\n",
    "cc_matrix, lags = cc_values(agg_reviews.rating, detrended_stocks)\n",
    "print(\"Maximum correlation index: \", cor_index:=np.unravel_index(np.argmax(cc_matrix, axis=None), cc_matrix.shape)[0], \"\\n\",\n",
    "        \"Correlation of: \", cc_matrix[cor_index])\n",
    "cc_plot(lags, cc_matrix, COMPANY)\n",
    "plt.savefig(f\"cross-correlation-{COMPANY}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY = \"Tesla\"\n",
    "agg_reviews, detrended_reviews, agg_stocks, detrended_stocks = pre_analysis(review_df, stock_df, COMPANY, '2020-01-01', '2022-10-01')\n",
    "\n",
    "cc_matrix, lags = cc_values(agg_reviews.rating, detrended_stocks)\n",
    "print(\"Maximum correlation index: \", cor_index:=np.unravel_index(np.argmax(cc_matrix, axis=None), cc_matrix.shape)[0], \"\\n\",\n",
    "        \"Correlation of: \", cc_matrix[cor_index])\n",
    "cc_plot(lags, cc_matrix, COMPANY)\n",
    "plt.savefig(f\"cross-correlation-{COMPANY}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('data-in-the-wild')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (default, Sep 12 2022, 10:38:29) [Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c060306597498da564ccdf32a784c5790932549cacff5c6731bcd4f1e7a4abb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
